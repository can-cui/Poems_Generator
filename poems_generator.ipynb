{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random,os,keras\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Input, Model, load_model\n",
    "from keras.layers import LSTM, Dropout, Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorModel(object):\n",
    "    def __init__(self, config):\n",
    "        self.model = True #使用一个训练好的模型\n",
    "        self.do_train = True\n",
    "        self.loaded_model = True\n",
    "        self.config = config\n",
    "\n",
    "        # 文件预处理\n",
    "        self.word2numF, self.num2word, self.words, self.files_content = preprocess_file(self.config)\n",
    "        \n",
    "        # 诗的list\n",
    "        self.poems = self.files_content.split(']')\n",
    "        # 诗的总数量\n",
    "        self.poems_num = len(self.poems)\n",
    "        \n",
    "        # 如果模型文件存在则直接加载模型，否则开始训练\n",
    "        if os.path.exists(self.config.weight_file) and self.loaded_model:\n",
    "            self.model = load_model(self.config.weight_file)\n",
    "        else:\n",
    "            self.train()\n",
    "\n",
    "    def build_model(self):\n",
    "        #建立模型\n",
    "        print('building model')\n",
    "\n",
    "        # 输入的dimension\n",
    "        input_tensor = Input(shape=(self.config.max_len, len(self.words)))\n",
    "        lstm = LSTM(512, return_sequences=True)(input_tensor)\n",
    "        dropout = Dropout(0.6)(lstm)\n",
    "        lstm = LSTM(256)(dropout)\n",
    "        dropout = Dropout(0.6)(lstm)\n",
    "        dense = Dense(len(self.words), activation='softmax')(dropout)\n",
    "        self.model = Model(inputs=input_tensor, outputs=dense)\n",
    "        optimizer = Adam(lr=self.config.learning_rate)\n",
    "        self.model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    def sample(self, preds, temperature=0.5):\n",
    "        '''\n",
    "        当temperature=1.0时，模型输出正常\n",
    "        当temperature=0.5时，模型输出比较open\n",
    "        当temperature=1.5时，模型输出比较保守\n",
    "        在训练的过程中可以看到temperature不同，结果也不同\n",
    "        就是一个概率分布变换的问题，保守的时候概率大的值变得更大，选择的可能性也更大\n",
    "        '''\n",
    "        preds = np.asarray(preds).astype('float64')\n",
    "        exp_preds = np.power(preds,1./temperature)\n",
    "        preds = exp_preds / np.sum(exp_preds)\n",
    "        pro = np.random.choice(range(len(preds)),1,p=preds)\n",
    "        return int(pro.squeeze())\n",
    "    \n",
    "    def next_sen(self, text,temperature =0.5):\n",
    "        #根据给出的第一句诗句，来生成古诗\n",
    "        if not self.model:\n",
    "            return\n",
    "        max_len = self.config.max_len\n",
    "        if len(text)<max_len:\n",
    "            print('length should not be less than ',max_len)\n",
    "            return\n",
    "\n",
    "        sentence = str(text[-max_len:])\n",
    "        generate = self._preds(sentence,length = 10-max_len,temperature=temperature)\n",
    "        return generate\n",
    "    \n",
    "    def _preds(self,sentence,length = 9,temperature = 0.5):\n",
    "        '''\n",
    "        sentence:预测输入值\n",
    "        lenth:预测出的字符串长度\n",
    "        供类内部调用，输入max_len长度字符串，返回length长度的预测值字符串\n",
    "        '''\n",
    "        sentence = sentence[:self.config.max_len]\n",
    "        generate = ''\n",
    "        for i in range(length):\n",
    "            pred = self._pred(sentence,temperature)\n",
    "            generate += pred\n",
    "            sentence = sentence[1:]+pred\n",
    "        return generate\n",
    "        \n",
    "        \n",
    "    def _pred(self,sentence,temperature = 0.5):\n",
    "        #内部使用方法，根据一串输入，返回单个预测字符\n",
    "        if len(sentence) < self.config.max_len:\n",
    "            print('in def _pred,length error ')\n",
    "            return\n",
    "        \n",
    "        sentence = sentence[-self.config.max_len:]\n",
    "        x_pred = np.zeros((1, self.config.max_len, len(self.words)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, self.word2numF(char)] = 1.\n",
    "        preds = self.model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = self.sample(preds,temperature=temperature)\n",
    "        next_char = self.num2word[next_index]\n",
    "        \n",
    "        return next_char\n",
    "\n",
    "    def data_generator(self):\n",
    "        #生成器生成数据\n",
    "        i = 0\n",
    "        while 1:\n",
    "            x = self.files_content[i: i + self.config.max_len]\n",
    "            y = self.files_content[i + self.config.max_len]\n",
    "\n",
    "            if ']' in x or ']' in y:\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            y_vec = np.zeros(\n",
    "                shape=(1, len(self.words)),\n",
    "                dtype=np.bool\n",
    "            )\n",
    "            y_vec[0, self.word2numF(y)] = 1.0\n",
    "\n",
    "            x_vec = np.zeros(\n",
    "                shape=(1, self.config.max_len, len(self.words)),\n",
    "                dtype=np.bool\n",
    "            )\n",
    "\n",
    "            for t, char in enumerate(x):\n",
    "                x_vec[0, t, self.word2numF(char)] = 1.0\n",
    "\n",
    "            yield x_vec, y_vec\n",
    "            i += 1\n",
    "    \n",
    "    def train(self):\n",
    "        '''训练模型'''\n",
    "        print('training')\n",
    "        number_of_epoch = len(self.files_content)-(self.config.max_len + 1)*self.poems_num\n",
    "        number_of_epoch /= self.config.batch_size \n",
    "        number_of_epoch = int(number_of_epoch / 1.5)\n",
    "        print('epoches = ',number_of_epoch)\n",
    "        print('poems_num = ',self.poems_num)\n",
    "        print('len(self.files_content) = ',len(self.files_content))\n",
    "\n",
    "        if not self.model:\n",
    "            self.build_model()\n",
    "\n",
    "        self.model.fit_generator(\n",
    "            generator=self.data_generator(),\n",
    "            verbose=True,\n",
    "            steps_per_epoch=self.config.batch_size,\n",
    "            epochs=number_of_epoch,\n",
    "            callbacks=[\n",
    "                keras.callbacks.ModelCheckpoint(self.config.weight_file, save_weights_only=False),\n",
    "                LambdaCallback(on_epoch_end=self.generate_sample_result)\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "from config import Config\n",
    "model = GeneratorModel(Config)\n",
    "print('model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "丘荚勍啄悰\n",
      "试彗皇夺堡\n",
      "枭扇潮樛人\n"
     ]
    }
   ],
   "source": [
    "#给出第一句话进行预测\n",
    "sen = model.next_sen('床前明月光')\n",
    "#给出想要诗句的个数\n",
    "for i in range(3):\n",
    "    sen = model.next_sen(sen)\n",
    "    print(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
